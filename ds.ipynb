{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Still missing stuff:\n",
                "* CNN is not yet implemented\n",
                "* Chris Mathy's favorite performance metric is not used\n",
                "* *Please add other things on this \"to do list\" that are missing*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Loading packages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import keras\n",
                "from keras import layers\n",
                "from keras.utils import np_utils\n",
                "from scipy.signal import medfilt\n",
                "from keras.datasets import mnist\n",
                "from sklearn import svm, metrics, datasets\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "import matplotlib.pyplot as plt\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "digits = datasets.load_digits()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Defining functions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Binarize images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define function for making binary\n",
                "def make_binary(img, threshold):\n",
                "\n",
                "    img[img >= threshold] = 255\n",
                "    img[img < threshold] = 0\n",
                "    \n",
                "    return img"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## GoL image processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define function for Game of Life\n",
                "def GoL(seed, n_generations):\n",
                "    # Empty list for appending generations to (and start with the seed)\n",
                "    generations = []\n",
                "    \n",
                "    # Append seed to list of generations\n",
                "    generations.append(seed)\n",
                "    \n",
                "    # Apply 1-layer 0-padding\n",
                "    seed = np.pad(seed, 1)\n",
                "\n",
                "    # Define n_rows and n_cols from shape of img\n",
                "    n_rows, n_cols = seed.shape\n",
                "\n",
                "    # Perform ticks\n",
                "    for i in range(n_generations):\n",
                "        # Create image for next step, for overwriting\n",
                "        generation = np.array(np.zeros(shape=(n_rows, n_cols), dtype=np.int32))\n",
                "        \n",
                "        # For loop that iterates over each cell in the array\n",
                "        for r in range(n_rows-2):\n",
                "            for c in range(n_cols-2):\n",
                "                \n",
                "                # seed[r+1, c+1] (the \"middle\" cell during each window) and sum_context (sum of all cells around \"middle\" cell in window) ...\n",
                "                # ... has the right information. Check with: print(seed[r+1, c+1]) and print(sum_context)\n",
                "                sum_context = seed[r, c] + seed[r, c+1] + seed[r, c+2] + seed[r+1, c] + seed[r+1, c+2] + seed[r+2, c] + seed[r+2, c+1] + seed[r+2, c+2]\n",
                "\n",
                "                # Any live cell with fewer than 2 or more than 3, dies\n",
                "                if seed[r+1, c+1] == 1*255:\n",
                "                    if sum_context < 2*255 or sum_context > 3*255:\n",
                "                        generation[r+1, c+1] = 0\n",
                "                \n",
                "                # Any live cell with two or three live neighbours lives, unchanged\n",
                "                if seed[r+1, c+1] == 1*255 and 4*255 > sum_context > 1*255:\n",
                "                    generation[r+1, c+1] = 1*255\n",
                "\n",
                "                # Any dead cell with exactly 3 three live neighbours will come to life\n",
                "                if seed[r+1, c+1] == 0 and sum_context == 3*255:\n",
                "                    generation[r+1, c+1] = 1*255\n",
                "        \n",
                "        # Assign newest generation as the new seed\n",
                "        seed = generation.copy()\n",
                "\n",
                "        # Append newest generation to list of generations \n",
                "        generations.append(generation[1:-1, 1:-1])\n",
                "    \n",
                "    return generations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 576x576 with 4 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Set arbitrary seed\n",
                "seed = np.array([[124, 34, 126, 0], [0, 255, 255, 74], [255, 0, 255, 0], [0, 170, 0, 178]])\n",
                "\n",
                "# Binarize with threshold = 125\n",
                "seed = make_binary(seed, 125)\n",
                "\n",
                "# Perform 7 steps of GoL\n",
                "generations = GoL(seed, 3)\n",
                "\n",
                "# Plot generations\n",
                "fig = plt.figure(figsize=(8, 8))\n",
                "columns = len(generations)//2\n",
                "rows = len(generations)//2\n",
                "for i in range(1, len(generations)+1):\n",
                "    generations[i-1]\n",
                "    fig.add_subplot(rows, columns, i)\n",
                "    plt.imshow(generations[i-1], cmap=\"gray_r\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MNIST\n",
                "* Load MNIST\n",
                "* Binarize MNIST\n",
                "* Perform steps of GoL on MNIST\n",
                "* *Perform steps of other cellular automata*\n",
                "* Show example of MNIST after GoL\n",
                "* *Show example of MNIST after other cellular automata*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 3 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Load data\n",
                "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
                "\n",
                "# Concatenate so that we may add validation set also\n",
                "X = np.concatenate((train_X, test_X), axis=0)\n",
                "y = np.concatenate((train_y, test_y), axis=0)\n",
                "\n",
                "# Subset for faster processing\n",
                "X = X[:1000]\n",
                "y = y[:1000]\n",
                "\n",
                "# Binarize MNIST (X, not y)\n",
                "X_bina = [make_binary(np.array(img.copy(), dtype=np.int32), 125) for img in X]\n",
                "\n",
                "# Perform GoL on MNIST\n",
                "X_GoL = [GoL(img, 3)[-1] for img in X_bina]\n",
                "\n",
                "# Perform ___ on MNIST ...\n",
                "\n",
                "# Perform ___ on MNIST ...\n",
                "\n",
                "# Perform ___ on MNIST ...\n",
                "\n",
                "X_sets = [X, X_bina, X_GoL] # Add the other image processing types to this list\n",
                "X_sets_names = [\"X\", \"X_bina\", \"X_GoL\"] # Add the other image processing types to this list\n",
                "\n",
                "# Plot\n",
                "fig = plt.figure()\n",
                "ax1 = fig.add_subplot(2,2,1)\n",
                "ax1.imshow(X[13], cmap='gray_r')\n",
                "ax1.title.set_text('Original image')\n",
                "ax2 = fig.add_subplot(2,2,2)\n",
                "ax2.imshow(X_bina[13], cmap=\"gray_r\")\n",
                "ax2.title.set_text('Binarized image')\n",
                "ax3 = fig.add_subplot(2,2,3)\n",
                "ax3.title.set_text('GoL image (3 iterations)')\n",
                "ax3.imshow(X_GoL[13], cmap=\"gray_r\")\n",
                "plt.tight_layout()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Machine learning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## LR, SVM and CNN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Lenovo\\miniconda3\\envs\\methods3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
                        "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
                        "\n",
                        "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
                        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
                        "Please also refer to the documentation for alternative solver options:\n",
                        "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
                        "  n_iter_i = _check_optimize_result(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/15\n",
                        "29/29 [==============================] - 2s 30ms/step - loss: 18.3333 - accuracy: 0.3522\n",
                        "Epoch 2/15\n",
                        "29/29 [==============================] - 1s 30ms/step - loss: 2.0829 - accuracy: 0.7056\n",
                        "Epoch 3/15\n",
                        "29/29 [==============================] - 1s 30ms/step - loss: 1.2492 - accuracy: 0.7444\n",
                        "Epoch 4/15\n",
                        "29/29 [==============================] - 1s 27ms/step - loss: 0.6904 - accuracy: 0.8044\n",
                        "Epoch 5/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.6166 - accuracy: 0.8478\n",
                        "Epoch 6/15\n",
                        "29/29 [==============================] - 1s 32ms/step - loss: 0.4480 - accuracy: 0.8900\n",
                        "Epoch 7/15\n",
                        "29/29 [==============================] - 1s 27ms/step - loss: 0.4181 - accuracy: 0.8700\n",
                        "Epoch 8/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 0.3822 - accuracy: 0.8867\n",
                        "Epoch 9/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 0.3342 - accuracy: 0.8989\n",
                        "Epoch 10/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.2861 - accuracy: 0.9133\n",
                        "Epoch 11/15\n",
                        "29/29 [==============================] - 1s 31ms/step - loss: 0.2522 - accuracy: 0.9111\n",
                        "Epoch 12/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.2175 - accuracy: 0.9311\n",
                        "Epoch 13/15\n",
                        "29/29 [==============================] - 1s 27ms/step - loss: 0.1805 - accuracy: 0.9500\n",
                        "Epoch 14/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.1612 - accuracy: 0.9522\n",
                        "Epoch 15/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.1518 - accuracy: 0.9600\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Lenovo\\miniconda3\\envs\\methods3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
                        "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
                        "\n",
                        "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
                        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
                        "Please also refer to the documentation for alternative solver options:\n",
                        "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
                        "  n_iter_i = _check_optimize_result(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/15\n",
                        "29/29 [==============================] - 2s 28ms/step - loss: 0.4603 - accuracy: 0.8967\n",
                        "Epoch 2/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.3224 - accuracy: 0.9278\n",
                        "Epoch 3/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 0.2853 - accuracy: 0.9322\n",
                        "Epoch 4/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.2385 - accuracy: 0.9367\n",
                        "Epoch 5/15\n",
                        "29/29 [==============================] - 1s 30ms/step - loss: 0.2559 - accuracy: 0.9478\n",
                        "Epoch 6/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.1845 - accuracy: 0.9667\n",
                        "Epoch 7/15\n",
                        "29/29 [==============================] - 1s 30ms/step - loss: 0.1570 - accuracy: 0.9633\n",
                        "Epoch 8/15\n",
                        "29/29 [==============================] - 1s 27ms/step - loss: 0.1667 - accuracy: 0.9533\n",
                        "Epoch 9/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 0.1280 - accuracy: 0.9711\n",
                        "Epoch 10/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.1641 - accuracy: 0.9589\n",
                        "Epoch 11/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 0.0904 - accuracy: 0.9833\n",
                        "Epoch 12/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.0893 - accuracy: 0.9744\n",
                        "Epoch 13/15\n",
                        "29/29 [==============================] - 1s 32ms/step - loss: 0.0768 - accuracy: 0.9789\n",
                        "Epoch 14/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.0841 - accuracy: 0.9789\n",
                        "Epoch 15/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 0.1123 - accuracy: 0.9689\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Lenovo\\miniconda3\\envs\\methods3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
                        "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
                        "\n",
                        "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
                        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
                        "Please also refer to the documentation for alternative solver options:\n",
                        "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
                        "  n_iter_i = _check_optimize_result(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/15\n",
                        "29/29 [==============================] - 1s 27ms/step - loss: 5.3006 - accuracy: 0.1689\n",
                        "Epoch 2/15\n",
                        "29/29 [==============================] - 1s 31ms/step - loss: 2.1473 - accuracy: 0.2544\n",
                        "Epoch 3/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 2.0056 - accuracy: 0.2956\n",
                        "Epoch 4/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 1.8581 - accuracy: 0.3656\n",
                        "Epoch 5/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 1.6830 - accuracy: 0.4233\n",
                        "Epoch 6/15\n",
                        "29/29 [==============================] - 1s 30ms/step - loss: 1.5528 - accuracy: 0.4567\n",
                        "Epoch 7/15\n",
                        "29/29 [==============================] - 1s 31ms/step - loss: 1.4552 - accuracy: 0.5056\n",
                        "Epoch 8/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 1.3576 - accuracy: 0.5444\n",
                        "Epoch 9/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 1.1901 - accuracy: 0.5767\n",
                        "Epoch 10/15\n",
                        "29/29 [==============================] - 1s 35ms/step - loss: 1.1397 - accuracy: 0.6344\n",
                        "Epoch 11/15\n",
                        "29/29 [==============================] - 1s 31ms/step - loss: 1.0190 - accuracy: 0.6567\n",
                        "Epoch 12/15\n",
                        "29/29 [==============================] - 1s 29ms/step - loss: 0.9732 - accuracy: 0.6811\n",
                        "Epoch 13/15\n",
                        "29/29 [==============================] - 1s 28ms/step - loss: 0.9390 - accuracy: 0.6811\n",
                        "Epoch 14/15\n",
                        "29/29 [==============================] - 1s 27ms/step - loss: 0.8946 - accuracy: 0.6956\n",
                        "Epoch 15/15\n",
                        "29/29 [==============================] - 1s 27ms/step - loss: 0.7834 - accuracy: 0.7522\n",
                        "\n",
                        " \n",
                        " Evaluation statistics for logistic regression on the dataset with image processing X:\n",
                        "[[11  0  0  0  0  0  0  0  0  0]\n",
                        " [ 0  7  1  0  0  0  0  0  0  0]\n",
                        " [ 1  0  8  1  0  0  0  0  0  0]\n",
                        " [ 0  0  0 10  0  0  0  0  0  0]\n",
                        " [ 0  0  0  0  6  0  0  0  0  0]\n",
                        " [ 0  0  0  1  1  7  0  0  1  0]\n",
                        " [ 0  0  0  0  0  0 12  0  0  0]\n",
                        " [ 0  1  0  0  0  0  0 13  0  0]\n",
                        " [ 0  0  0  0  0  0  0  0  5  0]\n",
                        " [ 1  0  0  1  1  0  0  1  1  9]]\n",
                        "                   0      1          2          3         4          5     6  \\\n",
                        "precision   0.846154  0.875   0.888889   0.769231  0.750000   1.000000   1.0   \n",
                        "recall      1.000000  0.875   0.800000   1.000000  1.000000   0.700000   1.0   \n",
                        "f1-score    0.916667  0.875   0.842105   0.869565  0.857143   0.823529   1.0   \n",
                        "support    11.000000  8.000  10.000000  10.000000  6.000000  10.000000  12.0   \n",
                        "\n",
                        "                   7         8          9  accuracy   macro avg  weighted avg  \n",
                        "precision   0.928571  0.714286   1.000000      0.88    0.877213      0.899603  \n",
                        "recall      0.928571  1.000000   0.642857      0.88    0.894643      0.880000  \n",
                        "f1-score    0.928571  0.833333   0.782609      0.88    0.872852      0.877014  \n",
                        "support    14.000000  5.000000  14.000000      0.88  100.000000    100.000000  \n",
                        "\n",
                        " \n",
                        " Evaluation statistics for SVM on the dataset with image processing X:\n",
                        "[[11  0  0  0  0  0  0  0  0  0]\n",
                        " [ 0  7  1  0  0  0  0  0  0  0]\n",
                        " [ 0  0  9  1  0  0  0  0  0  0]\n",
                        " [ 0  0  0 10  0  0  0  0  0  0]\n",
                        " [ 0  0  0  0  6  0  0  0  0  0]\n",
                        " [ 0  0  0  0  0 10  0  0  0  0]\n",
                        " [ 0  0  0  0  0  0 12  0  0  0]\n",
                        " [ 0  1  0  0  0  0  0 13  0  0]\n",
                        " [ 0  0  0  0  0  1  0  0  4  0]\n",
                        " [ 1  0  1  1  1  0  0  0  1  9]]\n",
                        "                   0      1          2          3         4          5     6  \\\n",
                        "precision   0.916667  0.875   0.818182   0.833333  0.857143   0.909091   1.0   \n",
                        "recall      1.000000  0.875   0.900000   1.000000  1.000000   1.000000   1.0   \n",
                        "f1-score    0.956522  0.875   0.857143   0.909091  0.923077   0.952381   1.0   \n",
                        "support    11.000000  8.000  10.000000  10.000000  6.000000  10.000000  12.0   \n",
                        "\n",
                        "                   7    8          9  accuracy   macro avg  weighted avg  \n",
                        "precision   1.000000  0.8   1.000000      0.91    0.900942      0.918323  \n",
                        "recall      0.928571  0.8   0.642857      0.91    0.914643      0.910000  \n",
                        "f1-score    0.962963  0.8   0.782609      0.91    0.901879      0.906844  \n",
                        "support    14.000000  5.0  14.000000      0.91  100.000000    100.000000  \n",
                        "\n",
                        " \n",
                        " Evaluation statistics for CNN on the dataset with image processing X:\n",
                        "[[11  0  0  0  0  0  0  0  0  0]\n",
                        " [ 0  7  1  0  0  0  0  0  0  0]\n",
                        " [ 0  0  9  1  0  0  0  0  0  0]\n",
                        " [ 0  0  0 10  0  0  0  0  0  0]\n",
                        " [ 0  0  0  0  6  0  0  0  0  0]\n",
                        " [ 0  0  0  0  0 10  0  0  0  0]\n",
                        " [ 0  0  0  0  0  0 12  0  0  0]\n",
                        " [ 0  0  0  0  0  0  0 14  0  0]\n",
                        " [ 0  0  0  0  0  0  0  0  5  0]\n",
                        " [ 1  0  0  1  0  0  0  2  0 10]]\n",
                        "                   0         1     2          3    4     5     6          7  \\\n",
                        "precision   0.916667  1.000000   0.9   0.833333  1.0   1.0   1.0   0.875000   \n",
                        "recall      1.000000  0.875000   0.9   1.000000  1.0   1.0   1.0   1.000000   \n",
                        "f1-score    0.956522  0.933333   0.9   0.909091  1.0   1.0   1.0   0.933333   \n",
                        "support    11.000000  8.000000  10.0  10.000000  6.0  10.0  12.0  14.000000   \n",
                        "\n",
                        "             8          9  accuracy   macro avg  weighted avg  \n",
                        "precision  1.0   1.000000      0.94    0.952500      0.946667  \n",
                        "recall     1.0   0.714286      0.94    0.948929      0.940000  \n",
                        "f1-score   1.0   0.833333      0.94    0.946561      0.938126  \n",
                        "support    5.0  14.000000      0.94  100.000000    100.000000  \n",
                        "\n",
                        " \n",
                        " Evaluation statistics for logistic regression on the dataset with image processing X_bina:\n",
                        "[[11  0  0  0  0  0  0  0  0  0]\n",
                        " [ 0  7  1  0  0  0  0  0  0  0]\n",
                        " [ 0  0  8  2  0  0  0  0  0  0]\n",
                        " [ 0  0  0 10  0  0  0  0  0  0]\n",
                        " [ 0  0  0  0  6  0  0  0  0  0]\n",
                        " [ 0  0  0  1  1  6  0  0  2  0]\n",
                        " [ 0  0  0  0  0  0 12  0  0  0]\n",
                        " [ 0  1  0  0  0  0  0 13  0  0]\n",
                        " [ 0  0  0  0  0  0  0  0  5  0]\n",
                        " [ 1  0  0  1  1  1  0  1  1  8]]\n",
                        "                   0      1          2          3         4          5     6  \\\n",
                        "precision   0.916667  0.875   0.888889   0.714286  0.750000   0.857143   1.0   \n",
                        "recall      1.000000  0.875   0.800000   1.000000  1.000000   0.600000   1.0   \n",
                        "f1-score    0.956522  0.875   0.842105   0.833333  0.857143   0.705882   1.0   \n",
                        "support    11.000000  8.000  10.000000  10.000000  6.000000  10.000000  12.0   \n",
                        "\n",
                        "                   7         8          9  accuracy   macro avg  weighted avg  \n",
                        "precision   0.928571  0.625000   1.000000      0.86    0.855556      0.883115  \n",
                        "recall      0.928571  1.000000   0.571429      0.86    0.877500      0.860000  \n",
                        "f1-score    0.928571  0.769231   0.727273      0.86    0.849506      0.855058  \n",
                        "support    14.000000  5.000000  14.000000      0.86  100.000000    100.000000  \n",
                        "\n",
                        " \n",
                        " Evaluation statistics for SVM on the dataset with image processing X_bina:\n",
                        "[[11  0  0  0  0  0  0  0  0  0]\n",
                        " [ 0  7  1  0  0  0  0  0  0  0]\n",
                        " [ 0  0 10  0  0  0  0  0  0  0]\n",
                        " [ 0  0  0 10  0  0  0  0  0  0]\n",
                        " [ 0  0  0  0  6  0  0  0  0  0]\n",
                        " [ 0  0  0  0  0 10  0  0  0  0]\n",
                        " [ 0  0  0  0  0  0 12  0  0  0]\n",
                        " [ 0  1  0  0  0  0  0 13  0  0]\n",
                        " [ 0  0  0  0  0  1  0  0  4  0]\n",
                        " [ 1  0  1  1  2  0  0  0  1  8]]\n",
                        "                   0      1          2          3         4          5     6  \\\n",
                        "precision   0.916667  0.875   0.833333   0.909091  0.750000   0.909091   1.0   \n",
                        "recall      1.000000  0.875   1.000000   1.000000  1.000000   1.000000   1.0   \n",
                        "f1-score    0.956522  0.875   0.909091   0.952381  0.857143   0.952381   1.0   \n",
                        "support    11.000000  8.000  10.000000  10.000000  6.000000  10.000000  12.0   \n",
                        "\n",
                        "                   7    8          9  accuracy   macro avg  weighted avg  \n",
                        "precision   1.000000  0.8   1.000000      0.91    0.899318      0.920985  \n",
                        "recall      0.928571  0.8   0.571429      0.91    0.917500      0.910000  \n",
                        "f1-score    0.962963  0.8   0.727273      0.91    0.899275      0.904664  \n",
                        "support    14.000000  5.0  14.000000      0.91  100.000000    100.000000  \n",
                        "\n",
                        " \n",
                        " Evaluation statistics for CNN on the dataset with image processing X_bina:\n",
                        "[[11  0  0  0  0  0  0  0  0  0]\n",
                        " [ 0  7  1  0  0  0  0  0  0  0]\n",
                        " [ 0  0  9  0  0  0  0  1  0  0]\n",
                        " [ 0  0  0  9  0  0  0  1  0  0]\n",
                        " [ 0  0  0  0  6  0  0  0  0  0]\n",
                        " [ 0  0  0  0  0 10  0  0  0  0]\n",
                        " [ 0  0  0  0  0  0 12  0  0  0]\n",
                        " [ 0  0  0  0  0  0  0 14  0  0]\n",
                        " [ 0  0  0  0  0  0  0  0  5  0]\n",
                        " [ 1  0  0  0  0  0  0  1  1 11]]\n",
                        "                   0         1     2          3    4     5     6          7  \\\n",
                        "precision   0.916667  1.000000   0.9   1.000000  1.0   1.0   1.0   0.823529   \n",
                        "recall      1.000000  0.875000   0.9   0.900000  1.0   1.0   1.0   1.000000   \n",
                        "f1-score    0.956522  0.933333   0.9   0.947368  1.0   1.0   1.0   0.903226   \n",
                        "support    11.000000  8.000000  10.0  10.000000  6.0  10.0  12.0  14.000000   \n",
                        "\n",
                        "                  8          9  accuracy   macro avg  weighted avg  \n",
                        "precision  0.833333   1.000000      0.94    0.947353      0.947794  \n",
                        "recall     1.000000   0.785714      0.94    0.946071      0.940000  \n",
                        "f1-score   0.909091   0.880000      0.94    0.942954      0.939727  \n",
                        "support    5.000000  14.000000      0.94  100.000000    100.000000  \n",
                        "\n",
                        " \n",
                        " Evaluation statistics for logistic regression on the dataset with image processing X_GoL:\n",
                        "[[4 0 0 2 1 2 2 0 0 0]\n",
                        " [0 3 0 0 0 2 1 0 0 2]\n",
                        " [1 0 3 0 1 1 1 1 2 0]\n",
                        " [1 0 1 4 0 1 0 1 1 1]\n",
                        " [0 0 1 1 1 0 0 0 0 3]\n",
                        " [1 1 1 0 1 5 1 0 0 0]\n",
                        " [2 1 2 0 1 0 4 0 0 2]\n",
                        " [1 1 2 0 0 1 0 8 0 1]\n",
                        " [0 1 0 0 0 0 0 2 1 1]\n",
                        " [2 2 1 0 0 4 3 1 0 1]]\n",
                        "                   0         1          2          3         4          5  \\\n",
                        "precision   0.333333  0.333333   0.272727   0.571429  0.200000   0.312500   \n",
                        "recall      0.363636  0.375000   0.300000   0.400000  0.166667   0.500000   \n",
                        "f1-score    0.347826  0.352941   0.285714   0.470588  0.181818   0.384615   \n",
                        "support    11.000000  8.000000  10.000000  10.000000  6.000000  10.000000   \n",
                        "\n",
                        "                   6          7         8          9  accuracy   macro avg  \\\n",
                        "precision   0.333333   0.615385  0.250000   0.090909      0.34    0.331295   \n",
                        "recall      0.333333   0.571429  0.200000   0.071429      0.34    0.328149   \n",
                        "f1-score    0.333333   0.592593  0.222222   0.080000      0.34    0.325165   \n",
                        "support    12.000000  14.000000  5.000000  14.000000      0.34  100.000000   \n",
                        "\n",
                        "           weighted avg  \n",
                        "precision      0.342380  \n",
                        "recall         0.340000  \n",
                        "f1-score       0.336771  \n",
                        "support      100.000000  \n",
                        "\n",
                        " \n",
                        " Evaluation statistics for SVM on the dataset with image processing X_GoL:\n",
                        "[[6 2 0 0 2 0 1 0 0 0]\n",
                        " [0 5 0 2 0 0 0 0 0 1]\n",
                        " [0 1 3 3 0 1 0 1 1 0]\n",
                        " [0 1 0 6 0 0 1 1 0 1]\n",
                        " [0 1 0 0 2 1 1 0 0 1]\n",
                        " [0 1 1 0 3 4 0 0 1 0]\n",
                        " [1 4 0 0 1 0 4 0 0 2]\n",
                        " [0 2 1 1 2 0 0 7 0 1]\n",
                        " [0 1 0 0 0 0 0 0 3 1]\n",
                        " [0 4 0 0 4 4 1 0 0 1]]\n",
                        "                   0         1     2          3         4     5          6  \\\n",
                        "precision   0.857143  0.227273   0.6   0.500000  0.142857   0.4   0.500000   \n",
                        "recall      0.545455  0.625000   0.3   0.600000  0.333333   0.4   0.333333   \n",
                        "f1-score    0.666667  0.333333   0.4   0.545455  0.200000   0.4   0.400000   \n",
                        "support    11.000000  8.000000  10.0  10.000000  6.000000  10.0  12.000000   \n",
                        "\n",
                        "                   7    8          9  accuracy   macro avg  weighted avg  \n",
                        "precision   0.777778  0.6   0.125000      0.41    0.473005      0.487428  \n",
                        "recall      0.500000  0.6   0.071429      0.41    0.430855      0.410000  \n",
                        "f1-score    0.608696  0.6   0.090909      0.41    0.424506      0.422490  \n",
                        "support    14.000000  5.0  14.000000      0.41  100.000000    100.000000  \n",
                        "\n",
                        " \n",
                        " Evaluation statistics for CNN on the dataset with image processing X_GoL:\n",
                        "[[7 0 0 2 0 0 1 0 0 1]\n",
                        " [0 4 0 0 0 0 0 1 1 2]\n",
                        " [0 0 4 1 0 2 0 2 0 1]\n",
                        " [0 0 0 6 0 1 1 1 0 1]\n",
                        " [1 0 1 0 1 0 1 1 1 0]\n",
                        " [2 0 0 0 1 3 0 0 2 2]\n",
                        " [0 2 0 2 3 1 4 0 0 0]\n",
                        " [0 0 0 1 1 0 0 8 3 1]\n",
                        " [0 0 0 1 0 0 0 0 2 2]\n",
                        " [1 0 0 2 3 0 0 0 0 8]]\n",
                        "                   0         1          2      3         4          5  \\\n",
                        "precision   0.636364  0.666667   0.800000   0.40  0.111111   0.428571   \n",
                        "recall      0.636364  0.500000   0.400000   0.60  0.166667   0.300000   \n",
                        "f1-score    0.636364  0.571429   0.533333   0.48  0.133333   0.352941   \n",
                        "support    11.000000  8.000000  10.000000  10.00  6.000000  10.000000   \n",
                        "\n",
                        "                   6          7         8          9  accuracy   macro avg  \\\n",
                        "precision   0.571429   0.615385  0.222222   0.444444      0.47    0.489619   \n",
                        "recall      0.333333   0.571429  0.400000   0.571429      0.47    0.447922   \n",
                        "f1-score    0.421053   0.592593  0.285714   0.500000      0.47    0.450676   \n",
                        "support    12.000000  14.000000  5.000000  14.000000      0.47  100.000000   \n",
                        "\n",
                        "           weighted avg  \n",
                        "precision      0.520916  \n",
                        "recall         0.470000  \n",
                        "f1-score       0.478117  \n",
                        "support      100.000000  \n"
                    ]
                }
            ],
            "source": [
                "# CNN model specifications\n",
                "batch_size = 128\n",
                "epochs = 15\n",
                "input_shape = (28, 28, 1)\n",
                "num_classes = len(set(y)) # Define number of classes\n",
                "cnn = keras.Sequential(\n",
                "    [\n",
                "        keras.Input(shape=input_shape),\n",
                "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
                "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
                "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
                "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
                "        layers.Flatten(),\n",
                "        layers.Dropout(0.5),\n",
                "        layers.Dense(num_classes, activation=\"softmax\"),\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Lists for appending each confusion matrix and classification report\n",
                "lr_cm = []\n",
                "lr_cr = []\n",
                "\n",
                "svm_cm = []\n",
                "svm_cr = []\n",
                "\n",
                "cnn_cm = []\n",
                "cnn_cr = []\n",
                "\n",
                "# Loop for fitting and validating\n",
                "for X in X_sets:\n",
                "    \n",
                "    # Split into train test\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .10, random_state=42)\n",
                "\n",
                "    # Flatten all 2D-arrays to 1D for LR and SVM\n",
                "    X_train_flat = [img.flatten() for img in X_train]\n",
                "    X_test_flat = [img.flatten() for img in X_test]\n",
                "\n",
                "    ############################################# Train + predict #############################################\n",
                "    # Train and predict LR\n",
                "    lr = LogisticRegression()\n",
                "    lr.fit(X_train_flat, y_train)\n",
                "    lr_predictions = lr.predict(X_test_flat)\n",
                "\n",
                "    # Train and predict SVM\n",
                "    clf = svm.SVC()\n",
                "    clf.fit(X_train_flat, y_train)\n",
                "    svm_predictions = clf.predict(X_test_flat)\n",
                "\n",
                "    # Train and predict CNN\n",
                "    X_train_cnn = np.expand_dims(X_train, -1) # Make sure each img has dimensions 28, 28, 1\n",
                "    X_test_cnn = np.expand_dims(X_test, -1)\n",
                "    y_train_cnn = keras.utils.np_utils.to_categorical(y_train, num_classes) # One-hot encoding of y \n",
                "    y_test_cnn = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
                "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) # Compile the model\n",
                "    cnn.fit(X_train_cnn, y_train_cnn, epochs=epochs) # Fit the model\n",
                "    cnn_predictions = cnn.predict(X_test_cnn) # Make predictions (outcome is in probabilites)\n",
                "    cnn_predictions = [np.argmax(cnn_prediction) for cnn_prediction in cnn_predictions] # to go from list of probabilities [0.8, 0.143, 0.03, ...] to the index of the highest probability\n",
                "\n",
                "    ############################################# Validate #############################################\n",
                "    # Validate LR\n",
                "    lr_cm.append(metrics.confusion_matrix(y_test, lr_predictions))\n",
                "    lr_cr.append(pd.DataFrame.from_dict(metrics.classification_report(y_test, lr_predictions, output_dict=True)))\n",
                "\n",
                "    # Validate LR\n",
                "    svm_cm.append(metrics.confusion_matrix(y_test, svm_predictions))\n",
                "    svm_cr.append(pd.DataFrame.from_dict(metrics.classification_report(y_test, svm_predictions, output_dict=True)))\n",
                "\n",
                "    # Validate CNN\n",
                "    cnn_cm.append(metrics.confusion_matrix(y_test, cnn_predictions))\n",
                "    cnn_cr.append(pd.DataFrame.from_dict(metrics.classification_report(y_test, cnn_predictions, output_dict=True)))\n",
                "\n",
                "# See performance for each X_set\n",
                "for i in range(len(X_sets_names)):\n",
                "    print(f\"\\n \\n Evaluation statistics for logistic regression on the dataset with image processing {X_sets_names[i]}:\")\n",
                "    print(lr_cm[i])\n",
                "    print(lr_cr[i])\n",
                "\n",
                "    print(f\"\\n \\n Evaluation statistics for SVM on the dataset with image processing {X_sets_names[i]}:\")\n",
                "    print(svm_cm[i])\n",
                "    print(svm_cr[i])\n",
                "\n",
                "    print(f\"\\n \\n Evaluation statistics for CNN on the dataset with image processing {X_sets_names[i]}:\")\n",
                "    print(cnn_cm[i])\n",
                "    print(cnn_cr[i])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Extra stuff (potentially useful?)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function for applying kernel any number of iterations with \"basic\" kernel\n",
                "def iterated_kernel(img, kernel, iterations):\n",
                "    \n",
                "    for i in range(iterations):\n",
                "        img = cv2.filter2D(img, -1, kernel)\n",
                "    \n",
                "    return img\n",
                "\n",
                "# Test function\n",
                "img_orig = np.array([[124, 125, 126, 0], [0, 255, 255, 0], [255, 0, 255, 0], [0, 0, 0, 0]])\n",
                "img_bina = make_binary(img_orig.copy(), 125)\n",
                "\n",
                "print(img_orig)\n",
                "print(img_bina)\n",
                "\n",
                "kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n",
                "\n",
                "cv2.filter2D(img_orig, -1, kernel)\n",
                "\n",
                "# img_iterated_once = iterated_kernel(img_bina, kernel, 1)\n",
                "# img_iterated_twice = iterated_kernel(img_bina, kernel, 2)\n",
                "\n",
                "# Plotting different versions\n",
                "fig = plt.figure()\n",
                "ax1 = fig.add_subplot(2,2,1)\n",
                "ax1.imshow(img_orig, cmap='gray_r')\n",
                "ax2 = fig.add_subplot(2,2,2)\n",
                "ax2.imshow(img_bina, cmap='gray_r')\n",
                "ax3 = fig.add_subplot(2,2,3)\n",
                "ax3.imshow(img_iterated_once, cmap='gray_r')\n",
                "ax4 = fig.add_subplot(2,2,4)\n",
                "ax4.imshow(img_iterated_twice, cmap='gray_r')"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "b42fe09ec23d058fd85667eff2b35da59ff2c64bdeabf5a44ad05d57fd35edbf"
        },
        "kernelspec": {
            "display_name": "Python 3.9.7 ('methods3')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
